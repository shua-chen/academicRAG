
<style data-mw-deduplicate="TemplateStyles:r886046785">.mw-parser-output .toclimit-2 .toclevel-1 ul,.mw-parser-output .toclimit-3 .toclevel-2 ul,.mw-parser-output .toclimit-4 .toclevel-3 ul,.mw-parser-output .toclimit-5 .toclevel-4 ul,.mw-parser-output .toclimit-6 .toclevel-5 ul,.mw-parser-output .toclimit-7 .toclevel-6 ul{display:none}</style><div class="toclimit-3"><meta property="mw:PageProp/toc"></div>
<div class="mw-heading mw-heading2"><h2 id="History">History</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Machine_learning&amp;action=edit&amp;section=1" title="Edit section: History"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">See also: <a href="https://en.wikipedia.org/wiki/Timeline_of_machine_learning" title="Timeline of machine learning">Timeline of machine learning</a></div>
<p>The term <i>machine learning</i> was coined in 1959 by <a href="https://en.wikipedia.org/wiki/Arthur_Samuel_(computer_scientist)" title="Arthur Samuel (computer scientist)">Arthur Samuel</a>, an <a href="https://en.wikipedia.org/wiki/IBM" title="IBM">IBM</a> employee and pioneer in the field of <a href="https://en.wikipedia.org/wiki/Computer_gaming" class="mw-redirect" title="Computer gaming">computer gaming</a> and <a href="https://en.wikipedia.org/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a>.<sup id="cite_ref-Samuel_8-0" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-Samuel-8"><span class="cite-bracket">[</span>8<span class="cite-bracket">]</span></a></sup><sup id="cite_ref-Kohavi_9-0" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-Kohavi-9"><span class="cite-bracket">[</span>9<span class="cite-bracket">]</span></a></sup> The synonym <i>self-teaching computers</i> was also used in this time period.<sup id="cite_ref-cyberthreat_10-0" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-cyberthreat-10"><span class="cite-bracket">[</span>10<span class="cite-bracket">]</span></a></sup><sup id="cite_ref-11" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-11"><span class="cite-bracket">[</span>11<span class="cite-bracket">]</span></a></sup>
</p><p>Although the earliest machine learning model was introduced in the 1950s when <a href="https://en.wikipedia.org/wiki/Arthur_Samuel_(computer_scientist)" title="Arthur Samuel (computer scientist)">Arthur Samuel</a> invented a <a href="https://en.wikipedia.org/wiki/Computer_program" title="Computer program">program</a> that calculated the winning chance in checkers for each side, the history of machine learning roots back to decades of human desire and effort to study human cognitive processes.<sup id="cite_ref-WhatIs_12-0" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-WhatIs-12"><span class="cite-bracket">[</span>12<span class="cite-bracket">]</span></a></sup> In 1949, <a href="https://en.wikipedia.org/wiki/Canadians" title="Canadians">Canadian</a> psychologist <a href="https://en.wikipedia.org/wiki/Donald_O._Hebb" title="Donald O. Hebb">Donald Hebb</a> published the book <i><a href="https://en.wikipedia.org/wiki/Organization_of_Behavior" title="Organization of Behavior">The Organization of Behavior</a></i>, in which he introduced a <a href="https://en.wikipedia.org/wiki/Hebbian_theory" title="Hebbian theory">theoretical neural structure</a> formed by certain interactions among <a href="https://en.wikipedia.org/wiki/Nerve_cells" class="mw-redirect" title="Nerve cells">nerve cells</a>.<sup id="cite_ref-13" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-13"><span class="cite-bracket">[</span>13<span class="cite-bracket">]</span></a></sup> Hebb's model of <a href="https://en.wikipedia.org/wiki/Neuron" title="Neuron">neurons</a> interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or <a href="https://en.wikipedia.org/wiki/Artificial_neuron" title="Artificial neuron">artificial neurons</a> used by computers to communicate data.<sup id="cite_ref-WhatIs_12-1" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-WhatIs-12"><span class="cite-bracket">[</span>12<span class="cite-bracket">]</span></a></sup> Other researchers who have studied human <a href="https://en.wikipedia.org/wiki/Cognitive_systems_engineering" title="Cognitive systems engineering">cognitive systems</a> contributed to the modern machine learning technologies as well, including logician <a href="https://en.wikipedia.org/wiki/Walter_Pitts" title="Walter Pitts">Walter Pitts</a> and <a href="https://en.wikipedia.org/wiki/Warren_Sturgis_McCulloch" title="Warren Sturgis McCulloch">Warren McCulloch</a>, who proposed the early mathematical models of neural networks to come up with <a href="https://en.wikipedia.org/wiki/Algorithm" title="Algorithm">algorithms</a> that mirror human thought processes.<sup id="cite_ref-WhatIs_12-2" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-WhatIs-12"><span class="cite-bracket">[</span>12<span class="cite-bracket">]</span></a></sup>
</p><p>By the early 1960s, an experimental "learning machine" with <a href="https://en.wikipedia.org/wiki/Punched_tape" title="Punched tape">punched tape</a> memory, called Cybertron, had been developed by <a href="https://en.wikipedia.org/wiki/Raytheon_Company" class="mw-redirect" title="Raytheon Company">Raytheon Company</a> to analyse <a href="https://en.wikipedia.org/wiki/Sonar" title="Sonar">sonar</a> signals, <a href="https://en.wikipedia.org/wiki/Electrocardiography" title="Electrocardiography">electrocardiograms</a>, and speech patterns using rudimentary <a href="https://en.wikipedia.org/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a>. It was repetitively "trained" by a human operator/teacher to recognize patterns and equipped with a "<a href="https://en.wikipedia.org/wiki/Goof" title="Goof">goof</a>" button to cause it to reevaluate incorrect decisions.<sup id="cite_ref-14" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-14"><span class="cite-bracket">[</span>14<span class="cite-bracket">]</span></a></sup> A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.<sup id="cite_ref-15" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-15"><span class="cite-bracket">[</span>15<span class="cite-bracket">]</span></a></sup> Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.<sup id="cite_ref-16" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-16"><span class="cite-bracket">[</span>16<span class="cite-bracket">]</span></a></sup> In 1981 a report was given on using teaching strategies so that an <a href="https://en.wikipedia.org/wiki/Artificial_neural_network" class="mw-redirect" title="Artificial neural network">artificial neural network</a> learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.<sup id="cite_ref-17" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-17"><span class="cite-bracket">[</span>17<span class="cite-bracket">]</span></a></sup>
</p><p><a href="https://en.wikipedia.org/wiki/Tom_M._Mitchell" title="Tom M. Mitchell">Tom M. Mitchell</a> provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: "A computer program is said to learn from experience <i>E</i> with respect to some class of tasks <i>T</i> and performance measure <i>P</i> if its performance at tasks in <i>T</i>, as measured by <i>P</i>,  improves with experience <i>E</i>."<sup id="cite_ref-Mitchell-1997_18-0" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-Mitchell-1997-18"><span class="cite-bracket">[</span>18<span class="cite-bracket">]</span></a></sup> This definition of the tasks in which machine learning is concerned offers a fundamentally <a href="https://en.wikipedia.org/wiki/Operational_definition" title="Operational definition">operational definition</a> rather than defining the field in cognitive terms. This follows <a href="https://en.wikipedia.org/wiki/Alan_Turing" title="Alan Turing">Alan Turing</a>'s proposal in his paper "<a href="https://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence" title="Computing Machinery and Intelligence">Computing Machinery and Intelligence</a>", in which the question "Can machines think?" is replaced with the question "Can machines do what we (as thinking entities) can do?".<sup id="cite_ref-19" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-19"><span class="cite-bracket">[</span>19<span class="cite-bracket">]</span></a></sup>
</p><p>Modern-day machine learning has two objectives.  One is to classify data based on models which have been developed; the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. A machine learning algorithm for stock trading may inform the trader of future potential predictions.<sup id="cite_ref-20" class="reference"><a href="https://en.wikipedia.org/wiki/Machine_learning#cite_note-20"><span class="cite-bracket">[</span>20<span class="cite-bracket">]</span></a></sup>
